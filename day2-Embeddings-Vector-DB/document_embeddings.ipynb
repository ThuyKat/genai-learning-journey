{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete Guide: Document Embeddings, Eigenvalues & Eigenvectors\n",
    "## Jupyter Notebook Version with Full Examples and Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 1: SETUP AND IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 2: YOUR DOCUMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: What are your three documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define documents\n",
    "documents = {\n",
    "    'Doc1': 'dog barks loudly',\n",
    "    'Doc2': 'cat meows softly',\n",
    "    'Doc3': 'dog and cat play together'\n",
    "}\n",
    "\n",
    "print(\"Documents:\")\n",
    "print(\"=\"*50)\n",
    "for doc_name, content in documents.items():\n",
    "    print(f\"{doc_name}: \\\"{content}\\\"\")\n",
    "\n",
    "print(\"\\nVocabulary (5 unique words):\")\n",
    "vocabulary = ['dog', 'barks', 'cat', 'meows', 'play']\n",
    "for i, word in enumerate(vocabulary, 1):\n",
    "    print(f\"{i}. {word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: What's the relationship between these documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships = {\n",
    "    'Doc1 & Doc2': 'Completely different! No shared words. Doc1 about dogs, Doc2 about cats.',\n",
    "    'Doc1 & Doc3': 'Both mention \"dog\" - somewhat similar',\n",
    "    'Doc2 & Doc3': 'Both mention \"cat\" - somewhat similar',\n",
    "    'Doc3': 'Unique - combines both animals'\n",
    "}\n",
    "\n",
    "print(\"Document Relationships:\")\n",
    "print(\"=\"*50)\n",
    "for pair, relation in relationships.items():\n",
    "    print(f\"\\n{pair}:\")\n",
    "    print(f\"  → {relation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 3: CREATING THE WORD-DOCUMENT MATRIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3: How do we represent documents as a matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word-document matrix\n",
    "# Rows = words, Columns = documents\n",
    "\nA = np.array([\n",
    "    [1, 0, 1],  # dog\n",
    "    [1, 0, 0],  # barks\n",
    "    [0, 1, 1],  # cat\n",
    "    [0, 1, 0],  # meows\n",
    "    [0, 0, 1],  # play\n",
    "], dtype=float)\n",
    "\n# Create a nice dataframe for visualization\nA_df = pd.DataFrame(A, \n",
    "                    index=vocabulary,\n",
    "                    columns=['Doc1', 'Doc2', 'Doc3'])\n",
    "\nprint(\"Word-Document Matrix A (5 words × 3 documents):\")\nprint(\"=\"*50)\nprint(A_df)\nprint(f\"\\nMatrix shape: {A.shape} (5 words × 3 documents)\")\nprint(f\"Total numbers to track: {A.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4: What does each number mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Interpretation of Matrix A:\")\nprint(\"=\"*50)\nprint(f\"A[0,0] = {A[0,0]:.0f} means: 'dog' appears {A[0,0]:.0f} time in Doc1\")\nprint(f\"A[0,1] = {A[0,1]:.0f} means: 'dog' appears {A[0,1]:.0f} times in Doc2\")\nprint(f\"A[0,2] = {A[0,2]:.0f} means: 'dog' appears {A[0,2]:.0f} time in Doc3\")\nprint()\nprint(f\"A[1,0] = {A[1,0]:.0f} means: 'barks' appears {A[1,0]:.0f} time in Doc1\")\nprint(f\"A[1,1] = {A[1,1]:.0f} means: 'barks' appears {A[1,1]:.0f} times in Doc2\")\nprint()\nprint(f\"And so on for each word-document combination...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 4: TRANSPOSE - CHANGING PERSPECTIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5: What is the transpose of matrix A?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate transpose\nAt = A.T\n\n# Create dataframe for visualization\nAt_df = pd.DataFrame(At,\n",
    "                     index=['Doc1', 'Doc2', 'Doc3'],\n",
    "                     columns=vocabulary)\n",
    "\nprint(\"Transpose A^T (3 documents × 5 words):\")\nprint(\"=\"*50)\nprint(At_df)\nprint(f\"\\nTranspose shape: {At.shape} (3 documents × 5 words)\")\nprint(f\"\\nNotice: Rows and columns are FLIPPED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6: What's the difference in perspective?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PERSPECTIVE COMPARISON:\")\nprint(\"=\"*60)\nprint()\nprint(\"ORIGINAL A (Words × Documents perspective):\")\nprint(\"-\"*60)\nprint(\"'For each word, which documents contain it?'\")\nprint()\nprint(f\"Dog (row 0): {A[0]} → appears in Doc1, Doc3\")\nprint(f\"Barks (row 1): {A[1]} → appears in Doc1\")\nprint(f\"Cat (row 2): {A[2]} → appears in Doc2, Doc3\")\nprint()\nprint()\nprint(\"TRANSPOSE A^T (Documents × Words perspective):\")\nprint(\"-\"*60)\nprint(\"'For each document, which words does it contain?'\")\nprint()\nprint(f\"Doc1 (row 0): {At[0]} → contains: dog, barks\")\nprint(f\"Doc2 (row 1): {At[1]} → contains: cat, meows\")\nprint(f\"Doc3 (row 2): {At[2]} → contains: dog, cat, play\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 5: SIMILARITY MATRIX - A^T × A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q7: What is A^T × A?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate similarity matrix\nATA = At @ A\n\n# Create dataframe\nATA_df = pd.DataFrame(ATA,\n",
    "                     index=['Doc1', 'Doc2', 'Doc3'],\n",
    "                     columns=['Doc1', 'Doc2', 'Doc3'])\n\nprint(\"Similarity Matrix A^T × A (Documents × Documents):\")\nprint(\"=\"*50)\nprint(ATA_df.astype(int))\nprint(f\"\\nMatrix shape: {ATA.shape} (3 documents × 3 documents)\")\nprint(f\"\\nThis is a SQUARE matrix showing document relationships!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8: How is each entry calculated? (Step-by-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HOW TO CALCULATE A^T × A[0,0] (Doc1 with Doc1):\")\nprint(\"=\"*60)\nprint()\nprint(\"A^T × A[0,0] = (Row 0 of A^T) • (Column 0 of A)\")\nprint()\nprint(f\"Row 0 of A^T = {At[0]} (Doc1's words)\")\nprint(f\"Col 0 of A = {A[:, 0]} (Doc1's words)\")\nprint()\nprint(\"Dot product calculation:\")\ndot_prod = At[0] @ A[:, 0]\nprint(f\"  {At[0]} • {A[:, 0]}\")\nprint(f\"  = 1×1 + 1×1 + 0×0 + 0×0 + 0×0\")\nprint(f\"  = 1 + 1 + 0 + 0 + 0\")\nprint(f\"  = {int(dot_prod)}\")\nprint()\nprint(f\"Result: A^T × A[0,0] = {int(dot_prod)}\")\nprint(f\"Meaning: Doc1 has {int(dot_prod)} words total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q9: Calculate all entries step-by-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STEP-BY-STEP CALCULATION OF ALL ENTRIES:\")\nprint(\"=\"*60)\nprint()\n\nfor i in range(3):\n    for j in range(3):\n        result = At[i] @ A[:, j]\n        doc_i = ['Doc1', 'Doc2', 'Doc3'][i]\n        doc_j = ['Doc1', 'Doc2', 'Doc3'][j]\n        print(f\"A^T × A[{i},{j}] ({doc_i} with {doc_j}):\")\n        print(f\"  {At[i]} • {A[:, j]}\")\n        print(f\"  = {int(result)}\")\n        if i == j:\n            print(f\"  Meaning: {doc_i} has {int(result)} words\")\n        else:\n            print(f\"  Meaning: {doc_i} and {doc_j} share {int(result)} words\")\n        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10: Visualize the similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity matrix as heatmap\nfig, ax = plt.subplots(figsize=(8, 6))\nsns.heatmap(ATA_df, annot=True, fmt='.0f', cmap='YlOrRd', cbar=True, ax=ax)\nax.set_title('Document Similarity Matrix (A^T × A)\\nShowing word overlaps between documents', fontsize=14, fontweight='bold')\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nInterpretation:\")\nprint(f\"  • Diagonal (2, 2, 3): Word count in each document\")\nprint(f\"  • Off-diagonal (0, 1, 1): Shared words between documents\")\nprint(f\"  • Matrix is symmetric (mirror across diagonal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 6: EIGENVALUES AND EIGENVECTORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q11: Find eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate eigenvalues and eigenvectors\neigenvalues, eigenvectors = np.linalg.eig(ATA)\n\n# Sort by eigenvalues in descending order\nsorted_indices = np.argsort(eigenvalues)[::-1]\neigenvalues_sorted = eigenvalues[sorted_indices]\neigenvectors_sorted = eigenvectors[:, sorted_indices]\n\nprint(\"EIGENVALUES AND EIGENVECTORS:\")\nprint(\"=\"*60)\nprint()\nfor i in range(3):\n    print(f\"\\nEigenvector {i+1}:\")\n    print(\"-\"*60)\n    print(f\"v_{i+1} = {eigenvectors_sorted[:, i]}\")\n    print(f\"λ_{i+1} = {eigenvalues_sorted[i]:.1f}\")\n    pct = eigenvalues_sorted[i] / np.sum(eigenvalues_sorted) * 100\n    print(f\"Importance: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12: Verify the eigenvector property: A × v = λ × v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"VERIFICATION: A × v = λ × v\")\nprint(\"=\"*60)\nprint()\n\nfor i in range(3):\n    v = eigenvectors_sorted[:, i]\n    lam = eigenvalues_sorted[i]\n    \n    left_side = ATA @ v\n    right_side = lam * v\n    \n    match = np.allclose(left_side, right_side)\n    \n    print(f\"\\nEigenvector {i+1}:\")\n    print(\"-\"*60)\n    print(f\"A × v = {left_side}\")\n    print(f\"λ × v = {right_side}\")\n    print(f\"Match? {match} ✓\" if match else f\"Match? {match} ✗\")\n    print(f\"Difference: {np.linalg.norm(left_side - right_side):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q13: Interpret what each eigenvector means"
   ]
  },
  {
   "cell_type": {"cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpretations = {\n",
    "    1: {\n",
    "        'name': 'Single-animal vs Multi-animal Pattern',\n",
    "        'description': 'Separates documents focused on one animal from those with multiple animals',\n",
    "        'doc1': 'Single animal (dog)',\n",
    "        'doc2': 'Single animal (cat)',\n",
    "        'doc3': 'Multiple animals (dog + cat)'\n",
    "    },\n",
    "    2: {\n",
    "        'name': 'Dog vs Cat Pattern',\n",
    "        'description': 'Distinguishes dog-focused documents from cat-focused documents',\n",
    "        'doc1': 'Dog-focused (negative)',\n",
    "        'doc2': 'Cat-focused (positive)',\n",
    "        'doc3': 'Balanced/Neutral (zero)'\n",
    "    },\n",
    "    3: {\n",
    "        'name': 'Minor Details/Noise Pattern',\n",
    "        'description': 'Captures less important variations in the data',\n",
    "        'doc1': 'Minor detail',\n",
    "        'doc2': 'Minor detail',\n",
    "        'doc3': 'Minor detail (opposite)'\n",
    "    }\n",
    "}\n",
    "\nprint(\"INTERPRETATION OF EIGENVECTORS:\")\nprint(\"=\"*60)\nprint()\n\nfor i in range(1, 4):\n",
    "    interp = interpretations[i]\n",
    "    v = eigenvectors_sorted[:, i-1]\n",
    "    lam = eigenvalues_sorted[i-1]\n",
    "    pct = lam / np.sum(eigenvalues_sorted) * 100\n",
    "    \n",
    "    print(f\"\\nEigenvector {i} (λ={lam:.1f}, {pct:.1f}% importance):\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"Name: {interp['name']}\")\n",
    "    print(f\"Description: {interp['description']}\")\n",
    "    print(f\"\\nValues:\")\n",
    "    print(f\"  Doc1: {v[0]:.3f} → {interp['doc1']}\")\n",
    "    print(f\"  Doc2: {v[1]:.3f} → {interp['doc2']}\")\n",
    "    print(f\"  Doc3: {v[2]:.3f} → {interp['doc3']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q14: Visualize eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart of eigenvalues\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n# Bar chart of eigenvalues\nax = axes[0]\ncolors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\nax.bar(range(1, 4), eigenvalues_sorted, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\nax.set_xlabel('Eigenvalue Index', fontsize=12, fontweight='bold')\nax.set_ylabel('Eigenvalue', fontsize=12, fontweight='bold')\nax.set_title('Eigenvalues (Pattern Strengths)', fontsize=14, fontweight='bold')\nax.set_xticks([1, 2, 3])\nax.grid(axis='y', alpha=0.3)\nfor i, v in enumerate(eigenvalues_sorted):\n    ax.text(i+1, v+0.1, f'{v:.1f}', ha='center', fontweight='bold')\n\n# Pie chart of importance\nax = axes[1]\npercentages = eigenvalues_sorted / np.sum(eigenvalues_sorted) * 100\nwedges, texts, autotexts = ax.pie(percentages, labels=[f'Pattern {i+1}' for i in range(3)],\n                                    autopct='%1.1f%%', colors=colors, startangle=90,\n                                    textprops={'fontsize': 11, 'fontweight': 'bold'})\nax.set_title('Importance Distribution', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nEigenvalue Summary:\")\nfor i in range(3):\n    pct = eigenvalues_sorted[i] / np.sum(eigenvalues_sorted) * 100\n    print(f\"λ_{i+1} = {eigenvalues_sorted[i]:.1f} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 7: DOCUMENT EMBEDDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q15: Create document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document embeddings are the columns of eigenvectors\nembeddings = eigenvectors_sorted.T\n\n# Create dataframe\nembeddings_df = pd.DataFrame(embeddings,\n",
    "                            index=['Doc1', 'Doc2', 'Doc3'],\n",
    "                            columns=[f'Pattern {i+1}' for i in range(3)])\n\nprint(\"DOCUMENT EMBEDDINGS:\")\nprint(\"=\"*60)\nprint()\nprint(embeddings_df)\nprint()\nprint(\"Size comparison:\")\nprint(f\"  Old way (5 dimensions): 5 × 3 = 15 numbers\")\nprint(f\"  New way (3 dimensions): 3 × 3 = 9 numbers\")\nprint(f\"  Compression: {(1 - 9/15)*100:.0f}% smaller!\")\nprint(f\"  Information retained: {(4 + 2) / 7 * 100:.0f}% (if we keep first 2 patterns)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q16: What does each number in the embedding mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INTERPRETATION OF EMBEDDINGS:\")\nprint(\"=\"*60)\nprint()\n\nfor i, doc in enumerate(['Doc1', 'Doc2', 'Doc3']):\n    print(f\"\\n{doc}: {list(embeddings_df.loc[doc].values)}\")\n    print(\"-\"*60)\n    for j in range(3):\n        value = embeddings_df.loc[doc, f'Pattern {j+1}']\n        lam = eigenvalues_sorted[j]\n        pct = lam / np.sum(eigenvalues_sorted) * 100\n        print(f\"  Pattern {j+1} ({pct:.0f}%): {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q17: Find similar documents using embeddings"
   ]
  },
  {
   "cell_type": {"cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between documents\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nsimilarity_matrix = cosine_similarity(embeddings)\nsimilarity_df = pd.DataFrame(similarity_matrix,\n",
    "                            index=['Doc1', 'Doc2', 'Doc3'],\n",
    "                            columns=['Doc1', 'Doc2', 'Doc3'])\n\nprint(\"DOCUMENT SIMILARITY (using embeddings):\")\nprint(\"=\"*60)\nprint()\nprint(similarity_df.round(3))\nprint()\n\nprint(\"Interpretation:\")\nprint(f\"  Doc1 & Doc2 similarity: {similarity_df.loc['Doc1', 'Doc2']:.3f} (very different - opposite patterns)\")\nprint(f\"  Doc1 & Doc3 similarity: {similarity_df.loc['Doc1', 'Doc3']:.3f} (somewhat similar - share dog)\")\nprint(f\"  Doc2 & Doc3 similarity: {similarity_df.loc['Doc2', 'Doc3']:.3f} (somewhat similar - share cat)\")\nprint(f\"\\n  1.0 = identical, 0.0 = completely different\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q18: Visualize embeddings in 2D and 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D visualization\nfig = plt.figure(figsize=(15, 5))\n\n# 3D scatter plot\nax1 = fig.add_subplot(131, projection='3d')\ncolors_docs = ['red', 'blue', 'green']\nfor i, (doc, color) in enumerate(zip(['Doc1', 'Doc2', 'Doc3'], colors_docs)):\n    ax1.scatter(embeddings[i, 0], embeddings[i, 1], embeddings[i, 2], \n               s=500, c=color, alpha=0.7, edgecolors='black', linewidth=2, label=doc)\nax1.set_xlabel('Pattern 1 (57%)', fontweight='bold')\nax1.set_ylabel('Pattern 2 (29%)', fontweight='bold')\nax1.set_zlabel('Pattern 3 (14%)', fontweight='bold')\nax1.set_title('Embeddings in 3D Space', fontsize=12, fontweight='bold')\nax1.legend()\n\n# 2D projection (Pattern 1 vs Pattern 2)\nax2 = fig.add_subplot(132)\nfor i, (doc, color) in enumerate(zip(['Doc1', 'Doc2', 'Doc3'], colors_docs)):\n    ax2.scatter(embeddings[i, 0], embeddings[i, 1], s=500, c=color, \n               alpha=0.7, edgecolors='black', linewidth=2, label=doc)\n    ax2.annotate(doc, (embeddings[i, 0], embeddings[i, 1]), \n                xytext=(5, 5), textcoords='offset points', fontweight='bold')\nax2.set_xlabel('Pattern 1 (57%)', fontweight='bold')\nax2.set_ylabel('Pattern 2 (29%)', fontweight='bold')\nax2.set_title('Projection: Pattern 1 vs Pattern 2', fontsize=12, fontweight='bold')\nax2.grid(alpha=0.3)\nax2.legend()\nax2.axhline(y=0, color='k', linestyle='--', alpha=0.3)\nax2.axvline(x=0, color='k', linestyle='--', alpha=0.3)\n\n# 2D projection (Pattern 1 vs Pattern 3)\nax3 = fig.add_subplot(133)\nfor i, (doc, color) in enumerate(zip(['Doc1', 'Doc2', 'Doc3'], colors_docs)):\n    ax3.scatter(embeddings[i, 0], embeddings[i, 2], s=500, c=color, \n               alpha=0.7, edgecolors='black', linewidth=2, label=doc)\n    ax3.annotate(doc, (embeddings[i, 0], embeddings[i, 2]), \n                xytext=(5, 5), textcoords='offset points', fontweight='bold')\nax3.set_xlabel('Pattern 1 (57%)', fontweight='bold')\nax3.set_ylabel('Pattern 3 (14%)', fontweight='bold')\nax3.set_title('Projection: Pattern 1 vs Pattern 3', fontsize=12, fontweight='bold')\nax3.grid(alpha=0.3)\nax3.legend()\nax3.axhline(y=0, color='k', linestyle='--', alpha=0.3)\nax3.axvline(x=0, color='k', linestyle='--', alpha=0.3)\n\nplt.tight_layout()\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 8: THE THREE LEVELS OF MATHEMATICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q19: Level 1 - A × v = λ × v"
   ]
  },
  {
   "cell_type": {"cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LEVEL 1: A × v = λ × v\")\nprint(\"=\"*60)\nprint()\nprint(\"DEFINITION: For an eigenvector v with eigenvalue λ:\")\nprint(\"  When you apply matrix A to v, you just get v scaled by λ\")\nprint()\nprint(\"EXAMPLE with Eigenvector 1:\")\nprint(\"-\"*60)\n\nv1 = eigenvectors_sorted[:, 0]\nlam1 = eigenvalues_sorted[0]\n\nleft = ATA @ v1\nright = lam1 * v1\n\nprint(f\"\\nMatrix A:\")\nprint(ATA_df.astype(int))\nprint(f\"\\nEigenvector v₁ = {v1}\")\nprint(f\"Eigenvalue λ₁ = {lam1:.1f}\")\nprint(f\"\\nLeft side: A × v₁ = {left}\")\nprint(f\"Right side: λ₁ × v₁ = {lam1:.1f} × {v1}\")\nprint(f\"           = {right}\")\nprint(f\"\\nDo they match? {np.allclose(left, right)} ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q20: Level 2 - A × V = V × Λ"
   ]
  },
  {
   "cell_type": {"cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LEVEL 2: A × V = V × Λ\")\nprint(\"=\"*60)\nprint()\nprint(\"DEFINITION: Extend Level 1 to ALL eigenvectors at once\")\nprint()\n\nV = eigenvectors_sorted\nLambda = np.diag(eigenvalues_sorted)\n\nprint(f\"V (eigenvectors as columns):\")\nprint(V)\nprint()\nprint(f\"Λ (eigenvalues diagonal):\")\nprint(Lambda)\nprint()\n\nleft = ATA @ V\nright = V @ Lambda\n\nprint(f\"Left side: A × V =\")\nprint(left)\nprint()\nprint(f\"Right side: V × Λ =\")\nprint(right)\nprint()\nprint(f\"Do they match? {np.allclose(left, right)} ✓\")"
   ]
  },
  {
   "cell_type": {"cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q21: Level 3 - A = V × Λ × V^T"
   ]
  },
  {
   "cell_type": {"cell_type": {"cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LEVEL 3: A = V × Λ × V^T\")\nprint(\"=\"*60)\nprint()\nprint(\"DEFINITION: Express matrix as a product of components\")\nprint()\nprint(\"DERIVATION:\")\nprint(\"-\"*60)\nprint(\"Step 1: Start with Level 2\")\nprint(\"        A × V = V × Λ\")\nprint()\nprint(\"Step 2: Multiply both sides by V^T\")\nprint(\"        (A × V) × V^T = (V × Λ) × V^T\")\nprint()\nprint(\"Step 3: Use associativity\")\nprint(\"        A × (V × V^T) = V × Λ × V^T\")\nprint()\nprint(\"Step 4: Key insight - V × V^T = I\")\nVt = V.T\nVVt = V @ Vt\nprint(f\"        V × V^T = \")\nprint(np.round(VVt, 6))\nprint(\"        (This is the identity matrix!)\")\nprint()\nprint(\"Step 5: Substitute\")\nprint(\"        A × I = V × Λ × V^T\")\nprint()\nprint(\"Step 6: Simplify\")\nprint(\"        A = V × Λ × V^T\")\nprint()\nprint(\"VERIFICATION:\")\nprint(\"-\"*60)\nprint()\nreconstructed = V @ Lambda @ Vt\nprint(f\"Original A:\")\nprint(np.round(ATA, 4))\nprint()\nprint(f\"Reconstructed (V × Λ × V^T):\")\nprint(np.round(reconstructed, 4))\nprint()\nprint(f\"Difference:\")\nprint(np.round(reconstructed - ATA, 6))\nprint()\nprint(f\"Do they match? {np.allclose(reconstructed, ATA)} ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 9: COMPLETE WORKFLOW"
   ]
  },
  {
   "cell_type": {"cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\nprint(\"COMPLETE WORKFLOW: FROM DOCUMENTS TO EMBEDDINGS\")\nprint(\"=\"*80)\nprint()\nprint(\"INPUT: 3 documents with 5 unique words\")\nprint()\nprint(\"STEP 1: Create Word-Document Matrix A\")\nprint(\"-\"*80)\nprint(f\"Shape: {A.shape} (5 words × 3 documents)\")\nprint(f\"Numbers to track: {A.size}\")\nprint(A_df)\nprint()\nprint(\"STEP 2: Compute Transpose A^T\")\nprint(\"-\"*80)\nprint(f\"Shape: {At.shape} (3 documents × 5 words)\")\nprint(At_df)\nprint()\nprint(\"STEP 3: Calculate Similarity Matrix A^T × A\")\nprint(\"-\"*80)\nprint(f\"Shape: {ATA.shape} (3 documents × 3 documents)\")\nprint(ATA_df.astype(int))\nprint()\nprint(\"STEP 4: Find Eigenvalues and Eigenvectors\")\nprint(\"-\"*80)\nfor i in range(3):\n    lam = eigenvalues_sorted[i]\n    pct = lam / np.sum(eigenvalues_sorted) * 100\n    print(f\"  λ_{i+1} = {lam:.1f} ({pct:.1f}%) → v_{i+1} = {eigenvectors_sorted[:, i]}\")\nprint()\nprint(\"STEP 5: Create Document Embeddings\")\nprint(\"-\"*80)\nprint(f\"Shape: {embeddings.shape} (3 documents × 3 patterns)\")\nprint(embeddings_df.round(3))\nprint()\nprint(\"OUTPUT: Document embeddings that:\")\nprint(\"-\"*80)\nprint(f\"  • Are 60% smaller (9 vs 15 numbers)\")\nprint(f\"  • Retain 86% of information (57% + 29%)\")\nprint(f\"  • Capture semantic patterns\")\nprint(f\"  • Show document relationships\")\nprint(f\"  • Are ready for machine learning algorithms\")\nprint()\nprint(\"=\"*80)"
   ]
  },
  {
   "cell_type": {"cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION 10: SUMMARY AND CONCLUSIONS"
   ]
  },
  {
   "cell_type": {"cell_type": {"cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = \"\"\"\nCOMPLETE GUIDE SUMMARY\n════════════════════════════════════════════════════════════════════════════════\n\nYOU HAVE LEARNED:\n─────────────────────────────────────────────────────────────────────────────────\n\n1. MATRICES AND TRANSFORMATIONS\n   • How to represent documents as matrices\n   • What each element means\n   • How matrix operations work\n\n2. TRANSPOSE - CHANGING PERSPECTIVE\n   • What transpose means (flip rows ↔ columns)\n   • How it changes our perspective on data\n   • From words→documents to documents→words\n\n3. SIMILARITY MATRICES\n   • How to calculate A^T × A\n   • What each entry means (word overlap)\n   • How documents relate through shared words\n\n4. EIGENVALUES AND EIGENVECTORS\n   • The special property: A × v = λ × v\n   • Why eigenvectors are special directions\n   • How eigenvalues show importance\n   • Three fundamental patterns in your data\n\n5. DOCUMENT EMBEDDINGS\n   • How to compress documents (5 → 3 dimensions)\n   • What each number represents\n   • How to find similar documents\n\n6. THE THREE LEVELS OF MATHEMATICS\n   Level 1: A × v = λ × v (single eigenvector)\n   Level 2: A × V = V × Λ (all eigenvectors)\n   Level 3: A = V × Λ × V^T (matrix decomposition)\n\n7. PRACTICAL WORKFLOW\n   From documents → matrix → similarity → eigenanalysis → embeddings\n\nKEY INSIGHTS:\n─────────────────────────────────────────────────────────────────────────────────\n\n✓ Eigenvectors reveal the NATURAL PATTERNS in data\n✓ Eigenvalues show the IMPORTANCE of each pattern\n✓ Matrix decomposition shows the STRUCTURE of the matrix\n✓ Dimensionality reduction keeps what matters, drops noise\n✓ The same principles apply to:\n  - Text analysis (LSA)\n  - Image processing (PCA)\n  - Word embeddings (GloVe)\n  - Neural networks\n  - Machine learning in general\n\nNUMBERS IN YOUR EXAMPLE:\n─────────────────────────────────────────────────────────────────────────────────\n\n• λ₁ = 4.0 (57%) → Single vs Multiple animals pattern\n• λ₂ = 2.0 (29%) → Dog vs Cat pattern\n• λ₃ = 1.0 (14%) → Minor details pattern\n\nCOMPRESSION:\n─────────────────────────────────────────────────────────────────────────────────\n\nOld representation: 5 dimensions (15 numbers total)\nNew representation: 3 dimensions (9 numbers total)\nCompression: 60% smaller\nInformation retention: 86% (with top 2 patterns)\n\nAPPLICATIONS:\n─────────────────────────────────────────────────────────────────────────────────\n\n1. LSA (Latent Semantic Analysis) - Find hidden topics in documents\n2. PCA (Principal Component Analysis) - Reduce dimensions in any data\n3. SVD (Singular Value Decomposition) - Generalization of this technique\n4. GloVe - Create word embeddings\n5. Image processing - Compress and enhance images\n6. Recommendation systems - Find similar items\n7. Neural networks - Understand feature learning\n\nYOU ARE NOW READY TO:\n─────────────────────────────────────────────────────────────────────────────────\n\n✓ Understand document embeddings\n✓ Work with eigenanalysis in practice\n✓ Apply dimensionality reduction techniques\n✓ Build machine learning models\n✓ Understand how modern NLP works\n✓ Explore advanced topics in data science\n\n════════════════════════════════════════════════════════════════════════════════\n\"\"\"\n\nprint(summary)"
   ]
  },
  {
   "cell_type": {"cell_type": {"cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a final summary table\nsummary_data = {\n    'Concept': ['Matrix A', 'Transpose A^T', 'Similarity (A^T×A)', 'Eigenvector 1', 'Eigenvector 2', 'Eigenvector 3', 'Embedding'],\n    'Meaning': ['Words × Documents', 'Documents × Words', 'Document relationships', 'Single vs Multi animals', 'Dog vs Cat', 'Minor details', 'Compressed representation'],\n    'Size': ['5×3 (15 nums)', '3×5 (15 nums)', '3×3 (9 nums)', '3 dims', '3 dims', '3 dims', '3×3 (9 nums)'],\n    'Importance': ['Starting data', 'Perspective flip', 'Similarity measure', '57%', '29%', '14%', '100%']\n}\n\nsummary_table = pd.DataFrame(summary_data)\nprint(\"\\nFINAL SUMMARY TABLE:\")\nprint(\"=\"*100)\nprint(summary_table.to_string(index=False))\nprint(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END OF NOTEBOOK\n",
    "\n",
    "This notebook has covered everything you need to understand document embeddings, eigenvalues, and eigenvectors with detailed examples and visualizations.\n",
    "\n",
    "Key takeaway: **The same mathematical principles that created your 3-dimensional document embeddings are used in modern NLP, image processing, and machine learning!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
